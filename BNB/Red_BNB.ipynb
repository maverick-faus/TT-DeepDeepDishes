{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Red_BNB.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"0oCs_jcGDN9D","colab_type":"text"},"cell_type":"markdown","source":["<img src=\"https://raw.githubusercontent.com/maverick-faus/Files/master/DeepDeamon2.png\" alt=\"drawing\" width=\"100px\"/>\n","# Red BNB - v1.2\n","TT: Deep Deep Dishes  \n","Food recommendation System  \n","ESCOM  \n","By Faus - 2K18\n"]},{"metadata":{"id":"HB702Uap0wMV","colab_type":"text"},"cell_type":"markdown","source":["**Instalación de TensorBoard para Collaboratory**"]},{"metadata":{"id":"CdXS3CpDMuAz","colab_type":"code","outputId":"2f42b360-561e-48db-f40c-e79ce54c4378","executionInfo":{"status":"ok","timestamp":1542827571308,"user_tz":360,"elapsed":7094,"user":{"displayName":"José Faustinos","photoUrl":"https://lh3.googleusercontent.com/-a6P7G5s5oIY/AAAAAAAAAAI/AAAAAAAAAI8/YHIp_dB4VOQ/s64/photo.jpg","userId":"04841510125594790710"}},"colab":{"base_uri":"https://localhost:8080/","height":181}},"cell_type":"code","source":["!pip install -U tensorboardcolab\n","from tensorboardcolab import *"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting tensorboardcolab\n","  Downloading https://files.pythonhosted.org/packages/73/3d/eaf745e162e471c5bb2737a407d8626fb8684a88cf085045456aeb841d3c/tensorboardcolab-0.0.19.tar.gz\n","Building wheels for collected packages: tensorboardcolab\n","  Running setup.py bdist_wheel for tensorboardcolab ... \u001b[?25l-\b \bdone\n","\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/ab/74/02/cda602d1dc28b2f12eab313c49b9bfa14d6371326bc2590e06\n","Successfully built tensorboardcolab\n","Installing collected packages: tensorboardcolab\n","Successfully installed tensorboardcolab-0.0.19\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"yLTvwKke04Pb","colab_type":"text"},"cell_type":"markdown","source":["**Instalación de biblioteca para acceso a Google Drive**"]},{"metadata":{"id":"rwexz-ikyJhM","colab_type":"code","outputId":"08eca7fc-3006-4cdb-d006-e316711fd811","executionInfo":{"status":"ok","timestamp":1542827579629,"user_tz":360,"elapsed":4943,"user":{"displayName":"José Faustinos","photoUrl":"https://lh3.googleusercontent.com/-a6P7G5s5oIY/AAAAAAAAAAI/AAAAAAAAAI8/YHIp_dB4VOQ/s64/photo.jpg","userId":"04841510125594790710"}},"colab":{"base_uri":"https://localhost:8080/","height":345}},"cell_type":"code","source":["!pip install PyDrive\n","import os\n","from zipfile import ZipFile\n","from shutil import copy\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting PyDrive\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/e0/0e64788e5dd58ce2d6934549676243dc69d982f198524be9b99e9c2a4fd5/PyDrive-1.3.1.tar.gz (987kB)\n","\r\u001b[K    1% |▎                               | 10kB 14.8MB/s eta 0:00:01\r\u001b[K    2% |▋                               | 20kB 4.4MB/s eta 0:00:01\r\u001b[K    3% |█                               | 30kB 6.2MB/s eta 0:00:01\r\u001b[K    4% |█▎                              | 40kB 4.2MB/s eta 0:00:01\r\u001b[K    5% |█▋                              | 51kB 5.0MB/s eta 0:00:01\r\u001b[K    6% |██                              | 61kB 5.8MB/s eta 0:00:01\r\u001b[K    7% |██▎                             | 71kB 6.6MB/s eta 0:00:01\r\u001b[K    8% |██▋                             | 81kB 7.3MB/s eta 0:00:01\r\u001b[K    9% |███                             | 92kB 8.1MB/s eta 0:00:01\r\u001b[K    10% |███▎                            | 102kB 6.7MB/s eta 0:00:01\r\u001b[K    11% |███▋                            | 112kB 6.8MB/s eta 0:00:01\r\u001b[K    12% |████                            | 122kB 8.9MB/s eta 0:00:01\r\u001b[K    13% |████▎                           | 133kB 8.7MB/s eta 0:00:01\r\u001b[K    14% |████▋                           | 143kB 14.6MB/s eta 0:00:01\r\u001b[K    15% |█████                           | 153kB 15.2MB/s eta 0:00:01\r\u001b[K    16% |█████▎                          | 163kB 15.3MB/s eta 0:00:01\r\u001b[K    17% |█████▋                          | 174kB 15.1MB/s eta 0:00:01\r\u001b[K    18% |██████                          | 184kB 15.4MB/s eta 0:00:01\r\u001b[K    19% |██████▎                         | 194kB 15.5MB/s eta 0:00:01\r\u001b[K    20% |██████▋                         | 204kB 31.1MB/s eta 0:00:01\r\u001b[K    21% |███████                         | 215kB 21.4MB/s eta 0:00:01\r\u001b[K    22% |███████▎                        | 225kB 22.0MB/s eta 0:00:01\r\u001b[K    23% |███████▋                        | 235kB 23.5MB/s eta 0:00:01\r\u001b[K    24% |████████                        | 245kB 23.6MB/s eta 0:00:01\r\u001b[K    25% |████████▎                       | 256kB 22.8MB/s eta 0:00:01\r\u001b[K    26% |████████▋                       | 266kB 21.1MB/s eta 0:00:01\r\u001b[K    27% |█████████                       | 276kB 21.7MB/s eta 0:00:01\r\u001b[K    29% |█████████▎                      | 286kB 21.6MB/s eta 0:00:01\r\u001b[K    30% |█████████▋                      | 296kB 21.4MB/s eta 0:00:01\r\u001b[K    31% |██████████                      | 307kB 22.4MB/s eta 0:00:01\r\u001b[K    32% |██████████▎                     | 317kB 36.8MB/s eta 0:00:01\r\u001b[K    33% |██████████▋                     | 327kB 37.1MB/s eta 0:00:01\r\u001b[K    34% |███████████                     | 337kB 37.6MB/s eta 0:00:01\r\u001b[K    35% |███████████▎                    | 348kB 34.1MB/s eta 0:00:01\r\u001b[K    36% |███████████▋                    | 358kB 35.5MB/s eta 0:00:01\r\u001b[K    37% |████████████                    | 368kB 40.0MB/s eta 0:00:01\r\u001b[K    38% |████████████▎                   | 378kB 40.3MB/s eta 0:00:01\r\u001b[K    39% |████████████▋                   | 389kB 40.8MB/s eta 0:00:01\r\u001b[K    40% |█████████████                   | 399kB 32.9MB/s eta 0:00:01\r\u001b[K    41% |█████████████▎                  | 409kB 33.6MB/s eta 0:00:01\r\u001b[K    42% |█████████████▋                  | 419kB 33.7MB/s eta 0:00:01\r\u001b[K    43% |██████████████                  | 430kB 32.9MB/s eta 0:00:01\r\u001b[K    44% |██████████████▎                 | 440kB 32.5MB/s eta 0:00:01\r\u001b[K    45% |██████████████▋                 | 450kB 32.1MB/s eta 0:00:01\r\u001b[K    46% |███████████████                 | 460kB 31.9MB/s eta 0:00:01\r\u001b[K    47% |███████████████▎                | 471kB 32.4MB/s eta 0:00:01\r\u001b[K    48% |███████████████▋                | 481kB 32.4MB/s eta 0:00:01\r\u001b[K    49% |████████████████                | 491kB 32.3MB/s eta 0:00:01\r\u001b[K    50% |████████████████▎               | 501kB 39.5MB/s eta 0:00:01\r\u001b[K    51% |████████████████▋               | 512kB 38.1MB/s eta 0:00:01\r\u001b[K    52% |█████████████████               | 522kB 39.0MB/s eta 0:00:01\r\u001b[K    53% |█████████████████▎              | 532kB 40.3MB/s eta 0:00:01\r\u001b[K    54% |█████████████████▋              | 542kB 39.3MB/s eta 0:00:01\r\u001b[K    55% |██████████████████              | 552kB 45.9MB/s eta 0:00:01\r\u001b[K    57% |██████████████████▎             | 563kB 46.8MB/s eta 0:00:01\r\u001b[K    58% |██████████████████▋             | 573kB 46.9MB/s eta 0:00:01\r\u001b[K    59% |███████████████████             | 583kB 47.4MB/s eta 0:00:01\r\u001b[K    60% |███████████████████▎            | 593kB 47.2MB/s eta 0:00:01\r\u001b[K    61% |███████████████████▋            | 604kB 47.8MB/s eta 0:00:01\r\u001b[K    62% |████████████████████            | 614kB 50.8MB/s eta 0:00:01\r\u001b[K    63% |████████████████████▎           | 624kB 48.9MB/s eta 0:00:01\r\u001b[K    64% |████████████████████▋           | 634kB 47.6MB/s eta 0:00:01\r\u001b[K    65% |█████████████████████           | 645kB 48.7MB/s eta 0:00:01\r\u001b[K    66% |█████████████████████▎          | 655kB 47.9MB/s eta 0:00:01\r\u001b[K    67% |█████████████████████▋          | 665kB 37.0MB/s eta 0:00:01\r\u001b[K    68% |██████████████████████          | 675kB 36.3MB/s eta 0:00:01\r\u001b[K    69% |██████████████████████▎         | 686kB 36.3MB/s eta 0:00:01\r\u001b[K    70% |██████████████████████▋         | 696kB 36.8MB/s eta 0:00:01\r\u001b[K    71% |███████████████████████         | 706kB 36.4MB/s eta 0:00:01\r\u001b[K    72% |███████████████████████▎        | 716kB 36.6MB/s eta 0:00:01\r\u001b[K    73% |███████████████████████▋        | 727kB 37.3MB/s eta 0:00:01\r\u001b[K    74% |████████████████████████        | 737kB 37.7MB/s eta 0:00:01\r\u001b[K    75% |████████████████████████▎       | 747kB 38.6MB/s eta 0:00:01\r\u001b[K    76% |████████████████████████▋       | 757kB 38.1MB/s eta 0:00:01\r\u001b[K    77% |████████████████████████▉       | 768kB 50.4MB/s eta 0:00:01\r\u001b[K    78% |█████████████████████████▏      | 778kB 51.3MB/s eta 0:00:01\r\u001b[K    79% |█████████████████████████▌      | 788kB 50.4MB/s eta 0:00:01\r\u001b[K    80% |█████████████████████████▉      | 798kB 49.9MB/s eta 0:00:01\r\u001b[K    81% |██████████████████████████▏     | 808kB 49.4MB/s eta 0:00:01\r\u001b[K    82% |██████████████████████████▌     | 819kB 49.0MB/s eta 0:00:01\r\u001b[K    83% |██████████████████████████▉     | 829kB 49.6MB/s eta 0:00:01\r\u001b[K    85% |███████████████████████████▏    | 839kB 50.6MB/s eta 0:00:01\r\u001b[K    86% |███████████████████████████▌    | 849kB 50.0MB/s eta 0:00:01\r\u001b[K    87% |███████████████████████████▉    | 860kB 45.7MB/s eta 0:00:01\r\u001b[K    88% |████████████████████████████▏   | 870kB 45.3MB/s eta 0:00:01\r\u001b[K    89% |████████████████████████████▌   | 880kB 46.2MB/s eta 0:00:01\r\u001b[K    90% |████████████████████████████▉   | 890kB 46.4MB/s eta 0:00:01\r\u001b[K    91% |█████████████████████████████▏  | 901kB 45.9MB/s eta 0:00:01\r\u001b[K    92% |█████████████████████████████▌  | 911kB 47.2MB/s eta 0:00:01\r\u001b[K    93% |█████████████████████████████▉  | 921kB 46.8MB/s eta 0:00:01\r\u001b[K    94% |██████████████████████████████▏ | 931kB 46.6MB/s eta 0:00:01\r\u001b[K    95% |██████████████████████████████▌ | 942kB 46.8MB/s eta 0:00:01\r\u001b[K    96% |██████████████████████████████▉ | 952kB 46.3MB/s eta 0:00:01\r\u001b[K    97% |███████████████████████████████▏| 962kB 51.9MB/s eta 0:00:01\r\u001b[K    98% |███████████████████████████████▌| 972kB 51.4MB/s eta 0:00:01\r\u001b[K    99% |███████████████████████████████▉| 983kB 50.4MB/s eta 0:00:01\r\u001b[K    100% |████████████████████████████████| 993kB 19.5MB/s \n","\u001b[?25hRequirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (1.6.7)\n","Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (4.1.3)\n","Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (3.13)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.0)\n","Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.11.3)\n","Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.11.0)\n","Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.2)\n","Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.4)\n","Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.0)\n","Building wheels for collected packages: PyDrive\n","  Running setup.py bdist_wheel for PyDrive ... \u001b[?25l-\b \bdone\n","\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/fa/d2/9a/d3b6b506c2da98289e5d417215ce34b696db856643bad779f4\n","Successfully built PyDrive\n","Installing collected packages: PyDrive\n","Successfully installed PyDrive-1.3.1\n"],"name":"stdout"}]},{"metadata":{"id":"YtWnVIZT1Bo_","colab_type":"text"},"cell_type":"markdown","source":["**Autenticación de usuario de Google Drive**"]},{"metadata":{"id":"EJp1EbfD0uq1","colab_type":"code","outputId":"370028a4-4fb1-4ac7-f056-4aaa4dfbb199","executionInfo":{"status":"ok","timestamp":1542827643390,"user_tz":360,"elapsed":61145,"user":{"displayName":"José Faustinos","photoUrl":"https://lh3.googleusercontent.com/-a6P7G5s5oIY/AAAAAAAAAAI/AAAAAAAAAI8/YHIp_dB4VOQ/s64/photo.jpg","userId":"04841510125594790710"}},"colab":{"base_uri":"https://localhost:8080/","height":383}},"cell_type":"code","source":["!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":3,"outputs":[{"output_type":"stream","text":["E: Package 'python-software-properties' has no installation candidate\n","Selecting previously unselected package libfuse2:amd64.\n","(Reading database ... 22298 files and directories currently installed.)\n","Preparing to unpack .../libfuse2_2.9.7-1ubuntu1_amd64.deb ...\n","Unpacking libfuse2:amd64 (2.9.7-1ubuntu1) ...\n","Selecting previously unselected package fuse.\n","Preparing to unpack .../fuse_2.9.7-1ubuntu1_amd64.deb ...\n","Unpacking fuse (2.9.7-1ubuntu1) ...\n","Selecting previously unselected package google-drive-ocamlfuse.\n","Preparing to unpack .../google-drive-ocamlfuse_0.7.0-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n","Unpacking google-drive-ocamlfuse (0.7.0-0ubuntu1~ubuntu18.04.1) ...\n","Setting up libfuse2:amd64 (2.9.7-1ubuntu1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1) ...\n","Setting up fuse (2.9.7-1ubuntu1) ...\n","Setting up google-drive-ocamlfuse (0.7.0-0ubuntu1~ubuntu18.04.1) ...\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","··········\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","Please enter the verification code: Access token retrieved correctly.\n"],"name":"stdout"}]},{"metadata":{"id":"NWu9ykup1qXl","colab_type":"text"},"cell_type":"markdown","source":["**Agregar Drive como directorio**"]},{"metadata":{"id":"YlA0kwXo1a7V","colab_type":"code","colab":{}},"cell_type":"code","source":["!mkdir -p drive\n","!google-drive-ocamlfuse drive"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pz8kh9In1eoL","colab_type":"code","outputId":"2409a80f-77b8-48d1-a5ed-6d8c3081f823","executionInfo":{"status":"ok","timestamp":1541437520651,"user_tz":360,"elapsed":3324,"user":{"displayName":"José Faustinos","photoUrl":"https://lh3.googleusercontent.com/-a6P7G5s5oIY/AAAAAAAAAAI/AAAAAAAAAI8/YHIp_dB4VOQ/s64/photo.jpg","userId":"04841510125594790710"}},"colab":{"base_uri":"https://localhost:8080/","height":617}},"cell_type":"code","source":["!ls drive"],"execution_count":0,"outputs":[{"output_type":"stream","text":["'Advanced Neural Networks'\n","'Artículos Varios TT'\n","'BBVA Hack - Chicos que lloran'\n","'Books Wishlist 2K18.ods'\n","'Books Wishlist 2K18.xlsx'\n","'Books Wishlist 2K18.xlsx.ods'\n"," Chatboot\n"," Classroom\n"," CodigoTT\n","'COMUNICADO Patish Complemento de Pago a sus proveedores.docx'\n","'COMUNICADO Patish Complemento de Pago a sus proveedores.odt'\n","'Copia de Red4B.ipynb'\n","'Curso DNN'\n","'Deep Daemon'\n"," deepdeep.backup\n","'Discurso excelencia.odt'\n","'Documento sin título.odt'\n","'Documentos Personales '\n","'Documento TT1'\n","'Documento TT1 (3a7c594f)'\n"," DriveC\n","'Hoja de cálculo sin título.ods'\n"," Imagenet_Hamburguer.ods\n"," IMG_2364Trim.mp4\n","'Prueba de Escritorio - DDD.ods'\n","'Publicidad dirigida mediante redes neuronales profundas.pdf'\n","'Retorno Inversiones Jose Shedid Merhy.xlsx'\n","'Retorno Inversiones Jose Shedid Merhy.xlsx.ods'\n","'Script Presentación TT1.odt'\n","'TT1 - Previos'\n"," TT2\n"," TT2_W2VReporteFinalFinal.docx\n"," Untitled0.ipynb\n"],"name":"stdout"}]},{"metadata":{"id":"SL6FzA0m1kY9","colab_type":"code","colab":{}},"cell_type":"code","source":["auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_iP4KUSxGtdO","colab_type":"code","colab":{}},"cell_type":"code","source":["fileIdLabelmap = '1_2gMy6MBqSiqMM1ybj3obdsrVMFEPezX'\n","#label map\n","downloaded1 = drive.CreateFile({'id': fileIdLabelmap})\n","downloaded1.GetContentFile(\"BNB_train.pickle\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1Z8M--H7HVpt","colab_type":"code","outputId":"b93e8dcb-6120-4e2e-f378-b593c18147df","executionInfo":{"status":"ok","timestamp":1541437556156,"user_tz":360,"elapsed":1891,"user":{"displayName":"José Faustinos","photoUrl":"https://lh3.googleusercontent.com/-a6P7G5s5oIY/AAAAAAAAAAI/AAAAAAAAAI8/YHIp_dB4VOQ/s64/photo.jpg","userId":"04841510125594790710"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["!ls\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["adc.json  BNB_train.pickle  drive  sample_data\n"],"name":"stdout"}]},{"metadata":{"id":"c8hq335iGPEf","colab_type":"code","colab":{}},"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","import pickle \n","from sklearn.metrics import confusion_matrix"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jGiRM_9SyJhW","colab_type":"code","colab":{}},"cell_type":"code","source":["def conv2d(x, W,name,padd,strid=[1,1,1,1]):\n","    #El stride de esa función no reduce el tamaño de la imagen\n","    return tf.nn.conv2d(x, W, strides=strid, padding=padd,name=name)\n","\n","def maxpool2d(x,ks,st):\n","    #           El st de esta función reduce la imagen a la mitad\n","    return tf.nn.max_pool(x, ksize=ks, strides=st, padding='SAME')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hIxZFWH_yJhb","colab_type":"code","colab":{}},"cell_type":"code","source":["def reset_graph():\n","    #Limpiamos la gráfic\n","    if 'sess' in globals() and sess:\n","        sess.close()\n","    tf.reset_default_graph()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"uPMoQzFgyJhe","colab_type":"code","colab":{}},"cell_type":"code","source":["def deep_neural_convolutional_class(\n","    batch_size=20,\n","    image_size=[200,200],\n","    Drop_prob=1.0,\n","    learning_rate = 1e-3,\n","    n_nodes_hl0 = 2000,\n","    n_nodes_hl1 = 1000,\n","    n_nodes_hl2 = 500,\n","    n_nodes_hl3 = 100,\n","    n_classes=2\n","    ):\n","    \n","    reset_graph()\n","    #Place holder de entrada \n","    x= tf.placeholder(tf.float32,[batch_size,image_size[0],image_size[1],3], name='placeholder_img_entrada')\n","    y=tf.placeholder(tf.float32,name='placeholder_one_hot')\n","  \n","    #Diccionario de pesos convolucionales \n","    with tf.name_scope('pesos_bias') as scope1:\n","        weigths={\"w_conv1\":tf.Variable(tf.random_normal([5,5,3,32]),name='Pesos_1_32'),\n","                 \"w_conv2\":tf.Variable(tf.random_normal([5,5,32,64]),name='Pesos_1_64'),\n","                 \"w_conv3\":tf.Variable(tf.random_normal([3,3,64,128]),name='Pesos_1_128'),   \n","                 \"w_conv4\":tf.Variable(tf.random_normal([5,5,128,256]),name='Pesos_1_256'),\n","                }\n","        #Diccionario de bias\n","        biases={\"b_conv1\":tf.Variable(tf.random_normal([32]),name='Bias_1_32'),\n","                \"b_conv2\":tf.Variable(tf.random_normal([64]),name='Bias_1_64'),\n","                \"b_conv3\":tf.Variable(tf.random_normal([128]),name='Bias_1_128'),\n","                \"b_conv4\":tf.Variable(tf.random_normal([256]),name='Bias_1_256'),\n","               }\n","\n","    #Extractor de características\n","    with tf.name_scope('capas_conv') as scope2:\n","        conv1=tf.nn.relu(conv2d(x,weigths[\"w_conv1\"],'Capa_Conv_1','SAME')+biases[\"b_conv1\"],name='Func_relu_1')\n","        conv1=tf.nn.dropout(conv1,Drop_prob)\n","        conv1=maxpool2d(conv1,ks=[1,2,2,1],st=[1,2,2,1])\n","        #imagen resultante de 100x100x32\n","        print(conv1)\n","\n","        conv2=tf.nn.relu(conv2d(conv1,weigths[\"w_conv2\"],'Capa_Conv_2','SAME')+biases[\"b_conv2\"],name='Func_relu_2')\n","        conv2=tf.nn.dropout(conv2,Drop_prob)\n","        conv2=maxpool2d(conv2,ks=[1,2,2,1],st=[1,2,2,1])\n","        #imagen resultante de 50x50x64\n","        print(conv2)\n","\n","        conv3=tf.nn.relu(conv2d(conv2,weigths[\"w_conv3\"],'Capa_Conv_3','VALID')+biases[\"b_conv3\"],name='Func_relu_3')\n","        conv3=tf.nn.dropout(conv3,Drop_prob)\n","        conv3=maxpool2d(conv3,ks=[1,2,2,1],st=[1,2,2,1])\n","        #imagen resultante de 24x24x128\n","        print(conv3)\n","\n","        conv4=tf.nn.relu(conv2d(conv3,weigths[\"w_conv4\"],'Capa_Conv_4','SAME')+biases[\"b_conv4\"],name='Func_relu_4')\n","        conv4=tf.nn.dropout(conv4,Drop_prob)\n","        conv4=maxpool2d(conv4,ks=[1,2,2,1],st=[1,2,2,1])\n","        #imagen resultante de 12x12x256\n","        print(conv4)\n","\n","        #Embeding, son las caracteristicas fonales que se pasarán al MLP o red completamente conectada para clasifiacar\n","        embdeding=tf.reshape(conv4,[batch_size,12*12*256],name='Embeding')\n","        print(embdeding)\n","    \n","    #Red perceptron, declaración de capas, son diccionarios de pesos y bias.\n","    with tf.name_scope('capas_clasificador') as scope3:\n","        hidden_0_layer = {'weights':tf.Variable(tf.random_normal([12*12*256, n_nodes_hl0]),name='Capa_oculta_pesos_0'),\n","                          'biases':tf.Variable(tf.random_normal([n_nodes_hl0]),name='Capa_oculta_bias_0')}\n","\n","        hidden_1_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl0, n_nodes_hl1]),'Capa_oculta_pesos_1'),\n","                          'biases':tf.Variable(tf.random_normal([n_nodes_hl1]),name='Capa_oculta_bias_1')}\n","\n","        hidden_2_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl1, n_nodes_hl2]),'Capa_oculta_pesos_2'),\n","                          'biases':tf.Variable(tf.random_normal([n_nodes_hl2]),name='Capa_oculta_bias_2')}\n","        \n","        hidden_3_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl2, n_nodes_hl3]),'Capa_oculta_pesos_3'),\n","                          'biases':tf.Variable(tf.random_normal([n_nodes_hl3]),name='Capa_oculta_bias_3')}\n","\n","        output_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl3, n_classes]),'Capa_salida_pesos'),\n","                        'biases':tf.Variable(tf.random_normal([n_classes]),name='Capa_salida_bias'),}\n","    \n","    #W*P + B \n","    with tf.name_scope('op_clasificador') as scope4:\n","        \n","        l0 = tf.add(tf.matmul(embdeding,hidden_0_layer['weights'],name='Matmul_l0'), hidden_0_layer['biases'],name='Suma_Pesos_Bias_0')\n","        l0 = tf.nn.relu(l0,name='l0_relu_0')\n","\n","        l1 = tf.add(tf.matmul(l0,hidden_1_layer['weights'],name='Matmul_l1'), hidden_1_layer['biases'],name='Suma_Pesos_Bias_1')\n","        l1 = tf.nn.relu(l1,name='l1_relu_1')\n","\n","        l2 = tf.add(tf.matmul(l1,hidden_2_layer['weights'],name='Matmul_l2'), hidden_2_layer['biases'],name='Suma_Pesos_Bias_2')\n","        l2 = tf.nn.relu(l2,name='l2_relu_2')\n","        \n","        l3 = tf.add(tf.matmul(l2,hidden_3_layer['weights'],name='Matmul_l3'), hidden_3_layer['biases'],name='Suma_Pesos_Bias_3')\n","        l3 = tf.nn.relu(l3,name='l3_relu_3')\n","\n","        output = tf.matmul(l3,output_layer['weights'],name='Matmul_out') + output_layer['biases']\n","    \n","    # Declarando la funcion de costo y entrenamiento\n","    #Reduce mean, reduce la dimension del tensor en un promedio es decir hace el promedio del costo o error\n","    \n","    \n","    with tf.name_scope('costo_y_optimizador') as scope5:\n","        cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(logits=output,labels=y,name='softmax_cross_entropy_with_logits1'),name='reduce_mean1')\n","        optimizer = tf.train.AdamOptimizer(name='Adam',learning_rate=learning_rate).minimize(cost,name='minimo')\n","    \n","    \n","    tf.summary.scalar(\"costo\",cost)\n","    correct = tf.equal(tf.argmax(output,1),tf.argmax(y,1),name='valores_correctos')\n","    accuracy = tf.reduce_mean(tf.cast(correct,'float'),name='Promedio_exactitud') #porcentaje de error\n","    \n","    tf.summary.scalar(\"accuracy\",accuracy)\n","    summaries = tf.summary.merge_all()\n","    \n","    return dict(\n","        x = x,\n","        y=y,\n","        embeding=conv4,\n","        output=output,\n","        saver = tf.train.Saver(),\n","        total_loss = cost,\n","        train_step = optimizer,\n","        summaries = summaries,\n","        accuracy = accuracy\n","    )"],"execution_count":0,"outputs":[]},{"metadata":{"id":"L1ELB1OfyJhh","colab_type":"code","outputId":"e12c3a8d-cd9d-4773-81f7-223a8f268169","executionInfo":{"status":"ok","timestamp":1542827740762,"user_tz":360,"elapsed":1776,"user":{"displayName":"José Faustinos","photoUrl":"https://lh3.googleusercontent.com/-a6P7G5s5oIY/AAAAAAAAAAI/AAAAAAAAAI8/YHIp_dB4VOQ/s64/photo.jpg","userId":"04841510125594790710"}},"colab":{"base_uri":"https://localhost:8080/","height":417}},"cell_type":"code","source":["deep_neural_convolutional_class()"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Tensor(\"capas_conv/MaxPool:0\", shape=(20, 100, 100, 32), dtype=float32)\n","Tensor(\"capas_conv/MaxPool_1:0\", shape=(20, 50, 50, 64), dtype=float32)\n","Tensor(\"capas_conv/MaxPool_2:0\", shape=(20, 24, 24, 128), dtype=float32)\n","Tensor(\"capas_conv/MaxPool_3:0\", shape=(20, 12, 12, 256), dtype=float32)\n","Tensor(\"capas_conv/Embeding:0\", shape=(20, 36864), dtype=float32)\n","WARNING:tensorflow:From <ipython-input-10-f392238367d4>:101: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["{'accuracy': <tf.Tensor 'Promedio_exactitud:0' shape=() dtype=float32>,\n"," 'embeding': <tf.Tensor 'capas_conv/MaxPool_3:0' shape=(20, 12, 12, 256) dtype=float32>,\n"," 'output': <tf.Tensor 'op_clasificador/add:0' shape=(20, 2) dtype=float32>,\n"," 'saver': <tensorflow.python.training.saver.Saver at 0x7f5d1bcf8b38>,\n"," 'summaries': <tf.Tensor 'Merge/MergeSummary:0' shape=() dtype=string>,\n"," 'total_loss': <tf.Tensor 'costo_y_optimizador/reduce_mean1:0' shape=() dtype=float32>,\n"," 'train_step': <tf.Operation 'costo_y_optimizador/minimo' type=NoOp>,\n"," 'x': <tf.Tensor 'placeholder_img_entrada:0' shape=(20, 200, 200, 3) dtype=float32>,\n"," 'y': <tf.Tensor 'placeholder_one_hot:0' shape=<unknown> dtype=float32>}"]},"metadata":{"tags":[]},"execution_count":11}]},{"metadata":{"id":"yp-mAXiDyJhn","colab_type":"code","colab":{}},"cell_type":"code","source":["def train_img_encoder(G,nameBatch,numbatch, num_epochs,learning_rate = 1e-2, \n","                      num_steps = 15, batch_size = 20, verbose = True, save=False,checkpoint=False):\n","    tf.set_random_seed(2345)\n","    tf.logging.set_verbosity(tf.logging.ERROR)\n","    print('Start training')\n","    total_loss = 0\n","    with tf.Session() as sess:\n","        \n","        writer = tf.summary.FileWriter(\"./CNNClass\")\n","        tf.summary.FileWriter.add_graph(writer,sess.graph)\n","        \n","        sess.run(tf.global_variables_initializer()) ###########\n","        #print('Enter here4')\n","        if checkpoint:\n","            ENCname=\"./\"+checkpoint+\".ckpt\"\n","            G['saver'].restore(sess, ENCname)\n","        training_losses = []\n","        for epoch in range(num_epochs):\n","            #print('ok')\n","            epoch_loss = 0\n","            for key in range(numbatch):\n","                data=np.array(pickle.load(open(nameBatch+\".pickle\",\"rb\")))\n","                dim,var=data.shape\n","                for j in range(int(dim/batch_size)):\n","                    epoch_x=data[batch_size*(j):batch_size*(j+1),0].tolist()\n","                    epoch_Y=data[batch_size*(j):batch_size*(j+1),1].tolist()\n","\n","                    feed_dict={G['x']: epoch_x,\n","                               G['y']: epoch_Y,\n","                              }\n","                \n","                    total_loss,_,summ,accuracy = sess.run([G[\"total_loss\"],G[\"train_step\"],G[\"summaries\"],G[\"accuracy\"]],feed_dict)\n","\n","                epoch_loss += total_loss\n","                writer.add_summary(summ,epoch)\n","                tbc.save_value(\"Loss\", \"loss\", epoch, epoch_loss)\n","                tbc.save_value(\"Accuracy\", \"accuracy\", epoch, accuracy)\n","                tbc.flush_line(\"loss\")\n","                tbc.flush_line(\"accuracy\")\n","            if verbose:\n","                print(\"Average training loss for Epoch\", epoch, \":\", epoch_loss)\n","            training_losses.append(epoch_loss)\n","      \n","        if isinstance(save, str):\n","            ENCname=\"drive/CodigoTT/BNB/ckptBNB/\"+save+\".ckpt\"\n","            G['saver'].save(sess, ENCname)       \n","        tbc.close()\n","    return training_losses"],"execution_count":0,"outputs":[]},{"metadata":{"id":"PsN5YLbR2Tc0","colab_type":"code","outputId":"3ba93f9b-2c05-4609-cdc5-c28864d158bc","executionInfo":{"status":"ok","timestamp":1542827763595,"user_tz":360,"elapsed":17505,"user":{"displayName":"José Faustinos","photoUrl":"https://lh3.googleusercontent.com/-a6P7G5s5oIY/AAAAAAAAAAI/AAAAAAAAAI8/YHIp_dB4VOQ/s64/photo.jpg","userId":"04841510125594790710"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"cell_type":"code","source":["tbc=TensorBoardColab()"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Wait for 8 seconds...\n","TensorBoard link:\n","http://9be2bb1f.ngrok.io\n"],"name":"stdout"}]},{"metadata":{"id":"XTzfiFYKyJhq","colab_type":"code","outputId":"51f6bf47-6e27-4e93-f403-33d8649594d4","executionInfo":{"status":"ok","timestamp":1541439940976,"user_tz":360,"elapsed":623356,"user":{"displayName":"José Faustinos","photoUrl":"https://lh3.googleusercontent.com/-a6P7G5s5oIY/AAAAAAAAAAI/AAAAAAAAAI8/YHIp_dB4VOQ/s64/photo.jpg","userId":"04841510125594790710"}},"colab":{"base_uri":"https://localhost:8080/","height":326}},"cell_type":"code","source":["path = \"BNB_train\"\n","encoder=deep_neural_convolutional_class(batch_size = 20)\n","train_img_encoder(encoder,path,1,num_epochs=15,save=\"BNB1\",batch_size = 20,verbose = True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Tensor(\"capas_conv/MaxPool:0\", shape=(20, 100, 100, 32), dtype=float32)\n","Tensor(\"capas_conv/MaxPool_1:0\", shape=(20, 50, 50, 64), dtype=float32)\n","Tensor(\"capas_conv/MaxPool_2:0\", shape=(20, 24, 24, 128), dtype=float32)\n","Tensor(\"capas_conv/MaxPool_3:0\", shape=(20, 12, 12, 256), dtype=float32)\n","Tensor(\"capas_conv/Embeding:0\", shape=(20, 36864), dtype=float32)\n","Start training\n","Average training loss for Epoch 0 : 5597262512128.0\n","Average training loss for Epoch 1 : 1060663328768.0\n","Average training loss for Epoch 2 : 86806994944.0\n","Average training loss for Epoch 3 : 484335747072.0\n","Average training loss for Epoch 4 : 2656910442496.0\n","Average training loss for Epoch 5 : 117250244608.0\n","Average training loss for Epoch 6 : 560080093184.0\n","Average training loss for Epoch 7 : 177584963584.0\n","Average training loss for Epoch 8 : 62041120768.0\n","Average training loss for Epoch 9 : 0.0\n","Average training loss for Epoch 10 : 32517154816.0\n"],"name":"stdout"}]},{"metadata":{"id":"epbcH8vqs9c1","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}